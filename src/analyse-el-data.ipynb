{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv eland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eland as ed\n",
    "import csv, json, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow import transpose, linalg, tensordot, dtypes, convert_to_tensor, keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from elasticsearch import Elasticsearch, NotFoundError, helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "EL_INDEX = 'heart'\n",
    "\n",
    "column_target = 'target'\n",
    "tf_model_name= 'tfmodel'\n",
    "epoch_amount=100\n",
    "columns_to_convert = [\n",
    "    # [EXPERIMENTAL] Add on this array all the columns you would like to convert to string\n",
    "    # 'example1',\n",
    "    # 'example2\n",
    "    'thal'\n",
    "]\n",
    "\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    \"http://elk-and-jupyter-elasticsearch-1:9200\",\n",
    "    basic_auth=(\"elastic\", os.getenv('ELASTIC_PASSWORD')),\n",
    ")\n",
    "print(es.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and Indexes data is on Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_into_el():\n",
    "    os.chdir('/home/jovyan/')\n",
    "    for filename in os.listdir(DATA_DIR):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            os.chdir(DATA_DIR)\n",
    "            with open(filename) as f:\n",
    "                ed.csv_to_eland(\n",
    "                    filename,\n",
    "                    es_client=es,\n",
    "                    es_dest_index=EL_INDEX,\n",
    "                    es_if_exists='replace',\n",
    "                    es_refresh=True\n",
    "                ) \n",
    "                #reader = csv.DictReader(f)\n",
    "                #helpers.bulk(es, reader, index=EL_INDEX)\n",
    "                os.chdir('../')\n",
    "        else: \n",
    "            if filename.endswith(\".json\"):\n",
    "                os.chdir(DATA_DIR)\n",
    "                with open(filename,'r') as open_file:\n",
    "                    helpers.bulk(es, json.load(open_file), index=EL_INDEX)\n",
    "                    os.chdir('../')\n",
    "    print('Done!')\n",
    "\n",
    "if es.indices.exists(index=EL_INDEX)==False:\n",
    "    print('Index Not found. Adding to ElasticSearch...')\n",
    "    insert_data_into_el()\n",
    "else:\n",
    "    print('Data is OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ed.DataFrame(es, es_index_pattern=EL_INDEX)\n",
    "#print(df.dtypes)\n",
    "pandas_df = ed.eland_to_pandas(df)\n",
    "\n",
    "def convert_string_column_to_numbers_tag(column_f):\n",
    "    pandas_df[column_f] = pd.Categorical(pandas_df[column_f])\n",
    "    pandas_df[column_f] = pandas_df.thal.cat.codes\n",
    "    # df_f[column_f] = pandas_df[column_f]\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    convert_string_column_to_numbers_tag(column)\n",
    "\n",
    "target = pandas_df.pop(column_target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pandas_df.values, target.values, test_size=.2)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "for feat, targ in dataset.take(5):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    tf.constant(pandas_df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(len(pandas_df)).batch(1)\n",
    "\n",
    "def get_compiled_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit, Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=epoch_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = [0 if val < 0.5 else 1 for val in y_hat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = './model/'+tf_model_name\n",
    "model.save(path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset into a 2D array of shape 18623 x 784\n",
    "x = convert_to_tensor(np.reshape(X_train, (X_train.shape[0], -1)),\n",
    "                      dtype=dtypes.float32)\n",
    "# Eigen-decomposition from a 784 x 784 matrix\n",
    "eigenvalues, eigenvectors = linalg.eigh(tensordot(transpose(x), x, axes=1))\n",
    "# Project the data to eigenvectors\n",
    "x_pca = tensordot(x, eigenvectors, axes=1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,6))\n",
    "\n",
    "# Create pandas DataFrame\n",
    "df_history = pd.DataFrame(history.history)\n",
    "\n",
    "# left plot\n",
    "scatter = ax[0].scatter(x_pca[:, -1], x_pca[:, -2], s=5, c=y_train)\n",
    "legend_plt = ax[0].legend(*scatter.legend_elements(),\n",
    "                         loc=\"lower left\", title=\"Digits\")\n",
    "ax[0].add_artist(legend_plt)\n",
    "ax[0].grid()\n",
    "ax[0].set_title('First Two Dimensions of Projected Data After Applying PCA')\n",
    "\n",
    "# middle plot\n",
    "training_graph = sns.lineplot(data=df_history[\"loss\"], ax=ax[1], color='orange')\n",
    "training_graph.set_xlabel('Epochs')\n",
    "training_graph.set_ylabel('Loss')\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Loss Overtime')\n",
    "\n",
    "# right plot\n",
    "accuracy_plot = sns.lineplot(data=df_history[\"accuracy\"], ax=ax[2], color='darkcyan')\n",
    "accuracy_plot.set_xlabel('Epochs')\n",
    "accuracy_plot.set_ylabel('Accuracy percentage')\n",
    "ax[2].set_title('Accuracy')\n",
    "ax[2].grid()\n",
    "plt.show()\n",
    "print('Accuracy score:', accuracy_score(y_test, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
